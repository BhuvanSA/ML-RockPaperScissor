{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!wget --no-check-certificate \\\n","    LINK \\\n","    -O /tmp/rps.zip\n","  \n","!wget --no-check-certificate \\\n","    LINK \\\n","    -O /tmp/rps-test-set.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PnYP_HhYNVUK"},"outputs":[],"source":["import os\n","import zipfile\n","\n","#local_zip = '/tmp/rps.zip'\n","#zip_ref = zipfile.ZipFile(local_zip, 'r')\n","#zip_ref.extractall('/tmp/')\n","#zip_ref.close()\n","\n","#local_zip = '/tmp/rps-test-set.zip'\n","#zip_ref = zipfile.ZipFile(local_zip, 'r')\n","#zip_ref.extractall('/tmp/')\n","#zip_ref.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MrxdR83ANgjS"},"outputs":[],"source":["rock_dir = os.path.join('/tmp/rps/rock')\n","paper_dir = os.path.join('/tmp/rps/paper')\n","scissors_dir = os.path.join('/tmp/rps/scissors')\n","\n","print('Total training rock images:', len(os.listdir(rock_dir)))\n","print('Total training paper images:', len(os.listdir(paper_dir)))\n","print('Total training scissors images:', len(os.listdir(scissors_dir)))\n","\n","rock_files = os.listdir(rock_dir)\n","print(rock_files[:10])\n","\n","paper_files = os.listdir(paper_dir)\n","print(paper_files[:10])\n","\n","scissors_files = os.listdir(scissors_dir)\n","print(scissors_files[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jp9dLel9N9DS"},"outputs":[],"source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","pic_index = 2\n","\n","next_rock = [os.path.join(rock_dir, fname) \n","                for fname in rock_files[pic_index-2:pic_index]]\n","next_paper = [os.path.join(paper_dir, fname) \n","                for fname in paper_files[pic_index-2:pic_index]]\n","next_scissors = [os.path.join(scissors_dir, fname) \n","                for fname in scissors_files[pic_index-2:pic_index]]\n","\n","for i, img_path in enumerate(next_rock+next_paper+next_scissors):\n","  #print(img_path)\n","  img = mpimg.imread(img_path)\n","  plt.imshow(img)\n","  plt.axis('Off')\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWTisYLQM1aM"},"outputs":[],"source":["import tensorflow as tf\n","import keras_preprocessing\n","from keras_preprocessing import image\n","from keras_preprocessing.image import ImageDataGenerator\n","\n","TRAINING_DIR = \"/tmp/rps/\"\n","training_datagen = ImageDataGenerator(\n","      rescale = 1./255,\n","\t  rotation_range=40,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n","\n","VALIDATION_DIR = \"/tmp/rps-test-set/\"\n","validation_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","train_generator = training_datagen.flow_from_directory(\n","\tTRAINING_DIR,\n","\ttarget_size=(150,150),\n","\tclass_mode='categorical'\n",")\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","\tVALIDATION_DIR,\n","\ttarget_size=(150,150),\n","\tclass_mode='categorical'\n",")\n","\n","model = tf.keras.models.Sequential([\n","    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n","    # This is the first convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    # The second convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The third convolution\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The fourth convolution\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # Flatten the results to feed into a DNN\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.5),\n","    # 512 neuron hidden layer\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(3, activation='softmax')\n","])\n","\n","\n","model.summary()\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","\n","history = model.fit_generator(train_generator, epochs=100, validation_data = validation_generator, verbose = 1)\n","\n","model.save(\"/content/rps.h5\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOAxFL1tcLyQ"},"outputs":[],"source":["!cp /content/rps.h5 /content/drive/MyDrive/rps.h5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aeTRVCr6aosw"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.legend(loc=0)\n","plt.figure()\n","\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZABJp7T3VLCU"},"outputs":[],"source":["import numpy as np\n","from google.colab import files\n","from keras.preprocessing import image\n","import keras.utils as image\n","\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n"," \n","  # predicting images\n","  path = fn\n","  img = image.load_img(path, target_size=(150, 150))\n","  x = image.img_to_array(img)\n","  x = np.expand_dims(x, axis=0)\n","\n","  images = np.vstack([x])\n","  classes = model.predict(images, batch_size=10)\n","  print(fn)\n","  print(classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dCI1-pZQSVx1"},"outputs":[],"source":["mod = tf.keras.models.load_model('/contents/rps.h5')\n","\n","mod.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szbsLllPDLI0"},"outputs":[],"source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","def take_photo(filename='/content/a.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","  data = eval_js('takePhoto({})'.format(quality))\n","  binary = b64decode(data.split(',')[1])\n","  with open(filename, 'wb') as f:\n","    f.write(binary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00mb-f0kCDvc"},"outputs":[],"source":["import tensorflow as tf\n","import cv2\n","import numpy as np\n","from keras.preprocessing import image\n","import keras.utils as image\n","\n","model = tf.keras.models.load_model(\"/content/rps.h5\")\n","\n","\n","model.summary()\n","cap = cv2.VideoCapture(0)\n","while cap.isOpened(): \n","  ret,frame = cap.read()\n","\n","  # cv2.imshow('ImageCollection',frame)\n","  #cv2.imwrite('/content/a.jpg',frame)\n","  take_photo()\n","  \n","    \n","  # predicting images\n","  path = '/content/a.jpg'\n","  img = image.load_img(path, target_size=(150, 150))\n","  x = image.img_to_array(img)\n","  x = np.expand_dims(x, axis=0)\n","\n","  images = np.vstack([x])\n","  \n","  \n","  classes = model.predict(images, batch_size=10)\n","  if classes[0,0] == 1:\n","    print(\"paper\")\n","  elif classes[0,1] == 1:\n","    print(\"rock\")\n","  elif classes[0,2] == 1:\n","    print(\"scissors\")\n","  \n","\n","  \n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/lmoroney/io19/blob/master/Zero%20to%20Hero/Rock-Paper-Scissors.ipynb","timestamp":1675578712254}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
